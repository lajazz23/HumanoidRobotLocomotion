{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Reinforcement Learning in Isaac Lab You can find my forked repository on GitHub . This resource is used to document my edits to the original Isaac Lab repository for my project. Project overview The Isaac Lab project is my project for the Summer 2025 SULI internship at Brookhaven National Lab. In this project, we build on top of the original Isaac Lab repository to create a trained Reinforcement Learning model using the Unitree G1 robot and RL Games . We implement Virtual Reality as a method of evaluation and interaction with the robots in the simulation. Why Humanoid Robots? Humanoid robots excel in human-centric environments. With little need for additional accommodations, humanoid robots exist as a practical tool for performing tasks that are unsafe, repetitive, or impractical for humans.\u200b Unitree G1 Robot The Unitree G1 robot was developed by Unitree Robotics, a Chinese company based in Hangzhou, China in 2024. Standing at 12.7 m tall, this humanoid robot is optimal for research and development due to its open-source SDK. Due to its compatibility with Isaac Lab, it is a great candidate for research in reinforcement learning with minimal transfer cost. Furthermore, the robot is compatible with virtual reality and teleoperation. In our project, the G1 robot has 37 joint motors, allowing for the performance of flexible tasks. Unitree H1 Robot The Unitree H1 is a bigger and more powerful robot compared to the G1. It is able to perform similar tasks, and excels in stability while performing locomotion tasks. The SDK is open-source, in C++, Python, and ROS2, easily allowing it to be worked on in research. Fourier GR-1 The Fourier GR-1 was developed by Fourier as a humanoid robot standing at 16.5 m tall. With built-in emotional systems, it mimics humans and can hold a proper human-robot conversation. It uses the Fourier Smart Actuator to integrate all movements into a single module. The GR1 has been deployed into industry to perform service tasks. While teleoperation is possible, it is not fully supported. Neo Neo Gamma is a humanoid robot designed for home use, developed by 1X, a tech company based in California. The robot is not bipedal, meaning that full-body locomotion cannot be tested. Neo uses embodied LLMs to learn its movements, making it easy to integrate AI agents. Furthermore, it is backed by OpenAI, allowing for longer-term support in its development. Poppy Humanoid Poppy is an open-source, 3D-printable humanoid robot created by the Flowers team at Inria. Poppy has been designed to be able to dance, walk, interact with humans, and perform. it contains 25-DoF with an actuated vertebral column. Berkeley Humanoid Lite The Berkeley Humanoid Lite is a robot designed at UC Berkely that is designed to be accessible and customizable. With parts widely available, the robot can be easily produced in any lab. With modular self-contained actuators and CAN communication, the robot can be configured with flexible joints and limbs. HopeJr HopeJr is an open-source robot developed by HuggingFace after their acquisition of Pollen Robotics. It contains 66 DoF, making it very versatile. With its integration into the LeRobot toolchain, it has access to data recording, teleoperation, and RL-based training. Author Jasmin Lin jlin3@bnl.gov","title":"Introduction"},{"location":"#reinforcement-learning-in-isaac-lab","text":"You can find my forked repository on GitHub . This resource is used to document my edits to the original Isaac Lab repository for my project.","title":"Reinforcement Learning in Isaac Lab"},{"location":"#project-overview","text":"The Isaac Lab project is my project for the Summer 2025 SULI internship at Brookhaven National Lab. In this project, we build on top of the original Isaac Lab repository to create a trained Reinforcement Learning model using the Unitree G1 robot and RL Games . We implement Virtual Reality as a method of evaluation and interaction with the robots in the simulation.","title":"Project overview"},{"location":"#why-humanoid-robots","text":"Humanoid robots excel in human-centric environments. With little need for additional accommodations, humanoid robots exist as a practical tool for performing tasks that are unsafe, repetitive, or impractical for humans.\u200b","title":"Why Humanoid Robots?"},{"location":"#unitree-g1-robot","text":"The Unitree G1 robot was developed by Unitree Robotics, a Chinese company based in Hangzhou, China in 2024. Standing at 12.7 m tall, this humanoid robot is optimal for research and development due to its open-source SDK. Due to its compatibility with Isaac Lab, it is a great candidate for research in reinforcement learning with minimal transfer cost. Furthermore, the robot is compatible with virtual reality and teleoperation. In our project, the G1 robot has 37 joint motors, allowing for the performance of flexible tasks.","title":"Unitree G1 Robot"},{"location":"#unitree-h1-robot","text":"The Unitree H1 is a bigger and more powerful robot compared to the G1. It is able to perform similar tasks, and excels in stability while performing locomotion tasks. The SDK is open-source, in C++, Python, and ROS2, easily allowing it to be worked on in research.","title":"Unitree H1 Robot"},{"location":"#fourier-gr-1","text":"The Fourier GR-1 was developed by Fourier as a humanoid robot standing at 16.5 m tall. With built-in emotional systems, it mimics humans and can hold a proper human-robot conversation. It uses the Fourier Smart Actuator to integrate all movements into a single module. The GR1 has been deployed into industry to perform service tasks. While teleoperation is possible, it is not fully supported.","title":"Fourier GR-1"},{"location":"#neo","text":"Neo Gamma is a humanoid robot designed for home use, developed by 1X, a tech company based in California. The robot is not bipedal, meaning that full-body locomotion cannot be tested. Neo uses embodied LLMs to learn its movements, making it easy to integrate AI agents. Furthermore, it is backed by OpenAI, allowing for longer-term support in its development.","title":"Neo"},{"location":"#poppy-humanoid","text":"Poppy is an open-source, 3D-printable humanoid robot created by the Flowers team at Inria. Poppy has been designed to be able to dance, walk, interact with humans, and perform. it contains 25-DoF with an actuated vertebral column.","title":"Poppy Humanoid"},{"location":"#berkeley-humanoid-lite","text":"The Berkeley Humanoid Lite is a robot designed at UC Berkely that is designed to be accessible and customizable. With parts widely available, the robot can be easily produced in any lab. With modular self-contained actuators and CAN communication, the robot can be configured with flexible joints and limbs.","title":"Berkeley Humanoid Lite"},{"location":"#hopejr","text":"HopeJr is an open-source robot developed by HuggingFace after their acquisition of Pollen Robotics. It contains 66 DoF, making it very versatile. With its integration into the LeRobot toolchain, it has access to data recording, teleoperation, and RL-based training.","title":"HopeJr"},{"location":"#author","text":"Jasmin Lin jlin3@bnl.gov","title":"Author"},{"location":"about/","text":"Description of Project Joint Indices Knowing the joint indices can be very helpful in changing reward parameters and customizing training. Unitree G1 The Unitree G1 robot in Isaac Sim comes pre-configured with a total of 37 joints: Index Joint Name Index Joint Name Index Joint Name Index Joint name 0 left hip pitch 12 right knee 24 left three 36 right two 1 right hip pitch 13 left shoulder yaw 26 left zero 2 torso 14 right shoulder yaw 27 right five 3 left hip roll 15 left ankle pitch 28 right three 4 right hip roll 16 right ankle pitch 29 right zero 5 left shoulder pitch 17 left elbow pitch 30 left six 6 right shoulder pitch 18 right elbow pitch 31 left four 7 left hip yaw 19 left ankle roll 32 left one 8 right hip yaw 20 right ankle roll 33 right six 9 left shoulder roll 21 left elbow roll 34 right four 10 right shoulder roll 22 right elbow roll 35 right one 11 left knee 23 left five 36 left two Unitree H1 The Unitree H1 comes in Isaac Sim with just 19 joints: Index Joint Name Index Joint Name 0 left hip yaw 10 right ankle 1 right hip yaw 11 left shoulder pitch 2 torso 12 right shoulder pitch 3 left hip roll 13 left shoulder roll 4 left hip pitch 14 left shoulder yaw 5 left knee 15 left elbow 6 left ankle 16 right shoulder roll 7 right hip roll 17 right shoulder yaw 8 right hip pitch 18 right elbow 9 right knee","title":"Project Structure"},{"location":"about/#description-of-project","text":"","title":"Description of Project"},{"location":"about/#joint-indices","text":"Knowing the joint indices can be very helpful in changing reward parameters and customizing training.","title":"Joint Indices"},{"location":"about/#unitree-g1","text":"The Unitree G1 robot in Isaac Sim comes pre-configured with a total of 37 joints: Index Joint Name Index Joint Name Index Joint Name Index Joint name 0 left hip pitch 12 right knee 24 left three 36 right two 1 right hip pitch 13 left shoulder yaw 26 left zero 2 torso 14 right shoulder yaw 27 right five 3 left hip roll 15 left ankle pitch 28 right three 4 right hip roll 16 right ankle pitch 29 right zero 5 left shoulder pitch 17 left elbow pitch 30 left six 6 right shoulder pitch 18 right elbow pitch 31 left four 7 left hip yaw 19 left ankle roll 32 left one 8 right hip yaw 20 right ankle roll 33 right six 9 left shoulder roll 21 left elbow roll 34 right four 10 right shoulder roll 22 right elbow roll 35 right one 11 left knee 23 left five 36 left two","title":"Unitree G1"},{"location":"about/#unitree-h1","text":"The Unitree H1 comes in Isaac Sim with just 19 joints: Index Joint Name Index Joint Name 0 left hip yaw 10 right ankle 1 right hip yaw 11 left shoulder pitch 2 torso 12 right shoulder pitch 3 left hip roll 13 left shoulder roll 4 left hip pitch 14 left shoulder yaw 5 left knee 15 left elbow 6 left ankle 16 right shoulder roll 7 right hip roll 17 right shoulder yaw 8 right hip pitch 18 right elbow 9 right knee","title":"Unitree H1"},{"location":"instruction/","text":"Getting Started With IsaacLab This section serves as instructions that I followed to successfully set up my Isaac Lab environment. Instructions are originally found on the Isaac Lab website . You can find their GitHub here . Requirements To determine if your current set up is optimal to run Isaac Lab and Isaac Sim, you can install the NVIDIA Isaac Sim compatibility checker, found in the Omniverse Launcher. It is important to know that, by October 2025, the Omniverse Launcher will be deprecated. You may reference the Isaac Lab website for minimum dependencies. Our project was run on the following specifications: NVIDIA GeForce RTX 4090 Driver Version 551.61 25.76 GB VRAM Intel(R) Core (TM) i9-14900KF 32 CPU cores 68.42 GB RAM 7315 GB Storage Windows 11 Pro v24H2 Anaconda 24.11.1 Installation Isaac Lab is built on top of Isaac Sim, so we will have to install that first. Our device is Windows-based. To find instructions for the Linux installation, please consult the Isaac Lab website. Isaac Sim To begin, we create a virtual environment called, \"isaaclab\" with python 3.10 inside Windows Terminal, and activate it. conda create -n isaaclab python=3.10 conda activate isaaclab Next, we install PyTorch that is compatible with our system's CUDA version. In this case, we had CUDA 12.4: pip install torch==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cu121 The Isaac Lab repository recommends updating pip: python -m pip install --upgrade pip To install the Isaac Sim packages, we ran the following: pip install \"isaacsim[all,extscache]==4.5.0\" --extra-index-url https://pypi.nvidia.com After this, Isaac Sim is fully installed. To test if this is true, we run isaacsim inside the terminal. After a few minutes, the Isaac Sim application will open, indicating a successful installation. Isaac Lab Next, we can begin the installation of Isaac Lab. To begin, clone the repository: git clone https://github.com/isaac-sim/IsaacLab.git Navigate into the folder and install Isaac Lab: cd IsaacLab isaaclab.bat --install After installation, open a demo file: isaaclab.bat -p scripts\\tutorials\\00_sim\\create_empty.py This should open Isaac Sim, with Isaac Lab inside it.","title":"Installation"},{"location":"instruction/#getting-started-with-isaaclab","text":"This section serves as instructions that I followed to successfully set up my Isaac Lab environment. Instructions are originally found on the Isaac Lab website . You can find their GitHub here .","title":"Getting Started With IsaacLab"},{"location":"instruction/#requirements","text":"To determine if your current set up is optimal to run Isaac Lab and Isaac Sim, you can install the NVIDIA Isaac Sim compatibility checker, found in the Omniverse Launcher. It is important to know that, by October 2025, the Omniverse Launcher will be deprecated. You may reference the Isaac Lab website for minimum dependencies. Our project was run on the following specifications: NVIDIA GeForce RTX 4090 Driver Version 551.61 25.76 GB VRAM Intel(R) Core (TM) i9-14900KF 32 CPU cores 68.42 GB RAM 7315 GB Storage Windows 11 Pro v24H2 Anaconda 24.11.1","title":"Requirements"},{"location":"instruction/#installation","text":"Isaac Lab is built on top of Isaac Sim, so we will have to install that first. Our device is Windows-based. To find instructions for the Linux installation, please consult the Isaac Lab website.","title":"Installation"},{"location":"instruction/#isaac-sim","text":"To begin, we create a virtual environment called, \"isaaclab\" with python 3.10 inside Windows Terminal, and activate it. conda create -n isaaclab python=3.10 conda activate isaaclab Next, we install PyTorch that is compatible with our system's CUDA version. In this case, we had CUDA 12.4: pip install torch==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cu121 The Isaac Lab repository recommends updating pip: python -m pip install --upgrade pip To install the Isaac Sim packages, we ran the following: pip install \"isaacsim[all,extscache]==4.5.0\" --extra-index-url https://pypi.nvidia.com After this, Isaac Sim is fully installed. To test if this is true, we run isaacsim inside the terminal. After a few minutes, the Isaac Sim application will open, indicating a successful installation.","title":"Isaac Sim"},{"location":"instruction/#isaac-lab","text":"Next, we can begin the installation of Isaac Lab. To begin, clone the repository: git clone https://github.com/isaac-sim/IsaacLab.git Navigate into the folder and install Isaac Lab: cd IsaacLab isaaclab.bat --install After installation, open a demo file: isaaclab.bat -p scripts\\tutorials\\00_sim\\create_empty.py This should open Isaac Sim, with Isaac Lab inside it.","title":"Isaac Lab"},{"location":"other/","text":"Other Information Reinforcement learning is used to train robots on movent, and excels in locomotion-based tasks. Vision-Language-Action Models Vision-Language-Action models are those that take in natural language as instruction to produce actions based on visual input. These models excel at high-level tasks. GR00T-N1.5 GR00T-N1.5 is NVIDIA's newest VLA that is capable of","title":"Other"},{"location":"other/#other-information","text":"Reinforcement learning is used to train robots on movent, and excels in locomotion-based tasks.","title":"Other Information"},{"location":"other/#vision-language-action-models","text":"Vision-Language-Action models are those that take in natural language as instruction to produce actions based on visual input. These models excel at high-level tasks.","title":"Vision-Language-Action Models"},{"location":"other/#gr00t-n15","text":"GR00T-N1.5 is NVIDIA's newest VLA that is capable of","title":"GR00T-N1.5"},{"location":"training/","text":"How Training Works in Isaac Lab In Isaac Lab, training is performed through Initiating Training python scripts/reinforcement_learning/skrl/train.py --task=Isaac-Velocity-Rough-G1-v0","title":"Training"},{"location":"training/#how-training-works-in-isaac-lab","text":"In Isaac Lab, training is performed through","title":"How Training Works in Isaac Lab"},{"location":"training/#initiating-training","text":"python scripts/reinforcement_learning/skrl/train.py --task=Isaac-Velocity-Rough-G1-v0","title":"Initiating Training"}]}